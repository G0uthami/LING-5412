{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project-Task 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNo0N_EnQ4_P"
      },
      "source": [
        "Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3tJs6Y6EOeG",
        "outputId": "bf0c9c39-5433-4536-9968-8dcc718d9ab9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywxS0cLrf_os",
        "outputId": "0671e5a8-efa8-4b12-aa19-5e7195f2e7a1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 11.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 38.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 448 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKwvU1AcRC_e"
      },
      "source": [
        "Importing All required Libraries and Loading Dataset into a Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "W8aBusMGEXkg",
        "outputId": "682dbc71-c688-4180-fd59-26b7e304bc1d"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "punctuations= string.punctuation\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "stopword_list = stopwords.words(\"english\")\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lem = WordNetLemmatizer()\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "import math\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "#import tokenizer\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix,f1_score,precision_recall_fscore_support,log_loss\n",
        "from sklearn.linear_model import Lasso, SGDClassifier,LogisticRegression as LR\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.decomposition import PCA,TruncatedSVD\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "import seaborn as sns\n",
        "import pylab as pl\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "def clean_text(text,stop_words=True):\n",
        "    cleaned_text = text.lower()\n",
        "    cleaned_text = \"\".join(c for c in cleaned_text if c not in punctuations)\n",
        "    words = cleaned_text.split()\n",
        "    if stop_words==True:\n",
        "      words = [w for w in words if w not in stopword_list]\n",
        "    words = [lem.lemmatize(word, \"v\") for word in words]\n",
        "    words = [lem.lemmatize(word, \"n\") for word in words]\n",
        "    cleaned_text = \" \".join(words)\n",
        "    return cleaned_text\n",
        "    \n",
        "path='/content/drive/My Drive/'\n",
        "with open(path+'dontpatronizeme_v1.4/dontpatronizeme_pcl.tsv') as f:\n",
        "  rows = f.read().split('\\n')[4:]\n",
        "  df =pd.DataFrame([i.split('\\t') for i in rows],columns=['par_id', 'art_id', 'keyword', 'country', 'text', 'label'])\n",
        "  l=[]\n",
        "  for i in df['label']:\n",
        "    if i ==0 or i==1:\n",
        "      l.append('No PCL')\n",
        "    else:\n",
        "      l.append('PCL')\n",
        "  df['original_label']=l\n",
        "for i in df.columns:\n",
        "  df[i]=df[i].apply(clean_text)\n",
        "#df['label'] = [int(i) for i in df['label']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_id</th>\n",
              "      <th>art_id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>original_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>24942188</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>ph</td>\n",
              "      <td>live time absolute insanity pretty sure people...</td>\n",
              "      <td>0</td>\n",
              "      <td>pcl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>21968160</td>\n",
              "      <td>migrant</td>\n",
              "      <td>gh</td>\n",
              "      <td>libya today countless number ghanaian nigerian...</td>\n",
              "      <td>0</td>\n",
              "      <td>pcl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>16584954</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>ie</td>\n",
              "      <td>white house press secretary sean spicer say fo...</td>\n",
              "      <td>0</td>\n",
              "      <td>pcl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>7811231</td>\n",
              "      <td>disable</td>\n",
              "      <td>nz</td>\n",
              "      <td>council customer sign would display two space ...</td>\n",
              "      <td>0</td>\n",
              "      <td>pcl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1494111</td>\n",
              "      <td>refugee</td>\n",
              "      <td>ca</td>\n",
              "      <td>like receive migrant flee el salvador guatemal...</td>\n",
              "      <td>0</td>\n",
              "      <td>pcl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  par_id    art_id  ... label original_label\n",
              "0      1  24942188  ...     0            pcl\n",
              "1      2  21968160  ...     0            pcl\n",
              "2      3  16584954  ...     0            pcl\n",
              "3      4   7811231  ...     0            pcl\n",
              "4      5   1494111  ...     0            pcl\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aLI3Dj-oFY9"
      },
      "source": [
        "**ML MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "zT0WiHLsoKqZ",
        "outputId": "bf24ddad-4c21-4899-fca4-f5d20f546a06"
      },
      "source": [
        "tfidf_transformer1 = TfidfVectorizer()\n",
        "x=df['text']\n",
        "y=df['label']\n",
        "x1= tfidf_transformer1.fit_transform(x)\n",
        "x1 = x1.toarray()\n",
        "pcas = PCA(500).fit(x1)\n",
        "x1 = pcas.transform(x1)\n",
        "dt=pd.DataFrame(x1)\n",
        "dt.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>460</th>\n",
              "      <th>461</th>\n",
              "      <th>462</th>\n",
              "      <th>463</th>\n",
              "      <th>464</th>\n",
              "      <th>465</th>\n",
              "      <th>466</th>\n",
              "      <th>467</th>\n",
              "      <th>468</th>\n",
              "      <th>469</th>\n",
              "      <th>470</th>\n",
              "      <th>471</th>\n",
              "      <th>472</th>\n",
              "      <th>473</th>\n",
              "      <th>474</th>\n",
              "      <th>475</th>\n",
              "      <th>476</th>\n",
              "      <th>477</th>\n",
              "      <th>478</th>\n",
              "      <th>479</th>\n",
              "      <th>480</th>\n",
              "      <th>481</th>\n",
              "      <th>482</th>\n",
              "      <th>483</th>\n",
              "      <th>484</th>\n",
              "      <th>485</th>\n",
              "      <th>486</th>\n",
              "      <th>487</th>\n",
              "      <th>488</th>\n",
              "      <th>489</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.012012</td>\n",
              "      <td>-0.043367</td>\n",
              "      <td>0.039508</td>\n",
              "      <td>-0.047414</td>\n",
              "      <td>0.022077</td>\n",
              "      <td>-0.031832</td>\n",
              "      <td>-0.014004</td>\n",
              "      <td>0.068254</td>\n",
              "      <td>-0.002538</td>\n",
              "      <td>0.058075</td>\n",
              "      <td>-0.003566</td>\n",
              "      <td>-0.014553</td>\n",
              "      <td>-0.013387</td>\n",
              "      <td>0.025226</td>\n",
              "      <td>-0.008143</td>\n",
              "      <td>-0.033696</td>\n",
              "      <td>0.023270</td>\n",
              "      <td>0.028396</td>\n",
              "      <td>0.022438</td>\n",
              "      <td>0.038161</td>\n",
              "      <td>0.018377</td>\n",
              "      <td>-0.005084</td>\n",
              "      <td>-0.010551</td>\n",
              "      <td>-0.017469</td>\n",
              "      <td>0.005503</td>\n",
              "      <td>0.000466</td>\n",
              "      <td>0.010052</td>\n",
              "      <td>-0.033586</td>\n",
              "      <td>-0.013652</td>\n",
              "      <td>0.020902</td>\n",
              "      <td>0.033782</td>\n",
              "      <td>-0.027533</td>\n",
              "      <td>0.011989</td>\n",
              "      <td>-0.028920</td>\n",
              "      <td>-0.030482</td>\n",
              "      <td>0.010439</td>\n",
              "      <td>0.011211</td>\n",
              "      <td>0.023833</td>\n",
              "      <td>0.004557</td>\n",
              "      <td>-0.024289</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029404</td>\n",
              "      <td>-0.022921</td>\n",
              "      <td>0.014913</td>\n",
              "      <td>-0.035322</td>\n",
              "      <td>-0.030175</td>\n",
              "      <td>-0.005661</td>\n",
              "      <td>-0.011427</td>\n",
              "      <td>-0.007382</td>\n",
              "      <td>-0.022622</td>\n",
              "      <td>-0.013059</td>\n",
              "      <td>-0.013909</td>\n",
              "      <td>0.022306</td>\n",
              "      <td>-0.005039</td>\n",
              "      <td>0.011876</td>\n",
              "      <td>0.019545</td>\n",
              "      <td>0.008543</td>\n",
              "      <td>0.010908</td>\n",
              "      <td>0.030069</td>\n",
              "      <td>0.002995</td>\n",
              "      <td>-0.037179</td>\n",
              "      <td>-0.013327</td>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.000768</td>\n",
              "      <td>-0.006526</td>\n",
              "      <td>-0.031632</td>\n",
              "      <td>0.046409</td>\n",
              "      <td>-0.016983</td>\n",
              "      <td>0.005627</td>\n",
              "      <td>0.023789</td>\n",
              "      <td>-0.023068</td>\n",
              "      <td>-0.007934</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.018430</td>\n",
              "      <td>0.013627</td>\n",
              "      <td>0.009391</td>\n",
              "      <td>0.019864</td>\n",
              "      <td>0.004096</td>\n",
              "      <td>0.032527</td>\n",
              "      <td>0.024831</td>\n",
              "      <td>-0.025416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.069546</td>\n",
              "      <td>0.030708</td>\n",
              "      <td>-0.073707</td>\n",
              "      <td>-0.030648</td>\n",
              "      <td>0.007586</td>\n",
              "      <td>0.021000</td>\n",
              "      <td>0.042132</td>\n",
              "      <td>-0.006712</td>\n",
              "      <td>-0.001857</td>\n",
              "      <td>0.043321</td>\n",
              "      <td>-0.008457</td>\n",
              "      <td>0.019736</td>\n",
              "      <td>0.014180</td>\n",
              "      <td>-0.022192</td>\n",
              "      <td>0.007465</td>\n",
              "      <td>0.076654</td>\n",
              "      <td>-0.015412</td>\n",
              "      <td>-0.026911</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>0.018212</td>\n",
              "      <td>-0.029738</td>\n",
              "      <td>-0.037651</td>\n",
              "      <td>-0.000594</td>\n",
              "      <td>0.003799</td>\n",
              "      <td>0.037853</td>\n",
              "      <td>0.009575</td>\n",
              "      <td>-0.021678</td>\n",
              "      <td>-0.010171</td>\n",
              "      <td>0.004117</td>\n",
              "      <td>-0.013084</td>\n",
              "      <td>0.027042</td>\n",
              "      <td>-0.059243</td>\n",
              "      <td>-0.042718</td>\n",
              "      <td>0.000726</td>\n",
              "      <td>0.019708</td>\n",
              "      <td>0.023014</td>\n",
              "      <td>0.001687</td>\n",
              "      <td>0.017208</td>\n",
              "      <td>0.006291</td>\n",
              "      <td>-0.050856</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003593</td>\n",
              "      <td>-0.010575</td>\n",
              "      <td>0.006235</td>\n",
              "      <td>-0.031366</td>\n",
              "      <td>0.035348</td>\n",
              "      <td>-0.046135</td>\n",
              "      <td>0.007838</td>\n",
              "      <td>-0.004402</td>\n",
              "      <td>0.012917</td>\n",
              "      <td>-0.019118</td>\n",
              "      <td>0.016102</td>\n",
              "      <td>-0.012693</td>\n",
              "      <td>-0.007588</td>\n",
              "      <td>0.020422</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>-0.015251</td>\n",
              "      <td>-0.016626</td>\n",
              "      <td>-0.047948</td>\n",
              "      <td>0.029048</td>\n",
              "      <td>-0.015984</td>\n",
              "      <td>-0.000964</td>\n",
              "      <td>-0.001927</td>\n",
              "      <td>0.010850</td>\n",
              "      <td>-0.011488</td>\n",
              "      <td>-0.005822</td>\n",
              "      <td>0.024316</td>\n",
              "      <td>0.036836</td>\n",
              "      <td>-0.009113</td>\n",
              "      <td>-0.018481</td>\n",
              "      <td>-0.003887</td>\n",
              "      <td>-0.030367</td>\n",
              "      <td>-0.000003</td>\n",
              "      <td>0.030725</td>\n",
              "      <td>-0.020159</td>\n",
              "      <td>0.017683</td>\n",
              "      <td>0.003844</td>\n",
              "      <td>0.003619</td>\n",
              "      <td>0.002024</td>\n",
              "      <td>0.002787</td>\n",
              "      <td>-0.037025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.067972</td>\n",
              "      <td>0.046724</td>\n",
              "      <td>-0.119317</td>\n",
              "      <td>-0.108371</td>\n",
              "      <td>-0.013408</td>\n",
              "      <td>-0.004236</td>\n",
              "      <td>0.055028</td>\n",
              "      <td>-0.021564</td>\n",
              "      <td>-0.046522</td>\n",
              "      <td>-0.147109</td>\n",
              "      <td>0.028385</td>\n",
              "      <td>-0.008314</td>\n",
              "      <td>0.043521</td>\n",
              "      <td>-0.093208</td>\n",
              "      <td>0.063468</td>\n",
              "      <td>0.008977</td>\n",
              "      <td>-0.037994</td>\n",
              "      <td>0.067008</td>\n",
              "      <td>-0.037547</td>\n",
              "      <td>-0.065254</td>\n",
              "      <td>0.032434</td>\n",
              "      <td>-0.056595</td>\n",
              "      <td>-0.011162</td>\n",
              "      <td>-0.017040</td>\n",
              "      <td>0.115892</td>\n",
              "      <td>0.122457</td>\n",
              "      <td>-0.020923</td>\n",
              "      <td>-0.034387</td>\n",
              "      <td>0.056888</td>\n",
              "      <td>0.044391</td>\n",
              "      <td>-0.038295</td>\n",
              "      <td>-0.015412</td>\n",
              "      <td>-0.002001</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>-0.024825</td>\n",
              "      <td>-0.022847</td>\n",
              "      <td>-0.002642</td>\n",
              "      <td>0.006353</td>\n",
              "      <td>-0.047042</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038479</td>\n",
              "      <td>0.005254</td>\n",
              "      <td>0.026058</td>\n",
              "      <td>0.020910</td>\n",
              "      <td>-0.039764</td>\n",
              "      <td>-0.025815</td>\n",
              "      <td>0.045875</td>\n",
              "      <td>0.011519</td>\n",
              "      <td>0.007412</td>\n",
              "      <td>0.002898</td>\n",
              "      <td>0.019004</td>\n",
              "      <td>-0.019890</td>\n",
              "      <td>-0.008834</td>\n",
              "      <td>0.022706</td>\n",
              "      <td>0.015691</td>\n",
              "      <td>0.024854</td>\n",
              "      <td>-0.029748</td>\n",
              "      <td>-0.008640</td>\n",
              "      <td>0.007007</td>\n",
              "      <td>-0.046176</td>\n",
              "      <td>0.007203</td>\n",
              "      <td>0.030823</td>\n",
              "      <td>-0.044738</td>\n",
              "      <td>0.009305</td>\n",
              "      <td>0.013758</td>\n",
              "      <td>-0.001588</td>\n",
              "      <td>-0.000605</td>\n",
              "      <td>0.013870</td>\n",
              "      <td>-0.005065</td>\n",
              "      <td>0.011817</td>\n",
              "      <td>-0.017777</td>\n",
              "      <td>0.000507</td>\n",
              "      <td>-0.005989</td>\n",
              "      <td>0.035424</td>\n",
              "      <td>-0.013751</td>\n",
              "      <td>0.003743</td>\n",
              "      <td>0.006045</td>\n",
              "      <td>-0.010895</td>\n",
              "      <td>-0.001175</td>\n",
              "      <td>-0.024603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.000930</td>\n",
              "      <td>-0.044648</td>\n",
              "      <td>0.008711</td>\n",
              "      <td>-0.026099</td>\n",
              "      <td>-0.018928</td>\n",
              "      <td>0.032586</td>\n",
              "      <td>-0.084687</td>\n",
              "      <td>0.030549</td>\n",
              "      <td>-0.075745</td>\n",
              "      <td>-0.025458</td>\n",
              "      <td>-0.028778</td>\n",
              "      <td>0.045685</td>\n",
              "      <td>0.080362</td>\n",
              "      <td>-0.005945</td>\n",
              "      <td>0.081811</td>\n",
              "      <td>-0.013460</td>\n",
              "      <td>-0.078120</td>\n",
              "      <td>0.043450</td>\n",
              "      <td>-0.148385</td>\n",
              "      <td>-0.133246</td>\n",
              "      <td>0.235941</td>\n",
              "      <td>0.019551</td>\n",
              "      <td>-0.036382</td>\n",
              "      <td>-0.030087</td>\n",
              "      <td>0.125784</td>\n",
              "      <td>-0.026027</td>\n",
              "      <td>0.131054</td>\n",
              "      <td>0.016813</td>\n",
              "      <td>0.076067</td>\n",
              "      <td>-0.017332</td>\n",
              "      <td>-0.021808</td>\n",
              "      <td>-0.023772</td>\n",
              "      <td>-0.000838</td>\n",
              "      <td>0.048174</td>\n",
              "      <td>-0.000281</td>\n",
              "      <td>-0.016075</td>\n",
              "      <td>0.043970</td>\n",
              "      <td>-0.010175</td>\n",
              "      <td>-0.068018</td>\n",
              "      <td>-0.043920</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013209</td>\n",
              "      <td>0.032637</td>\n",
              "      <td>-0.023945</td>\n",
              "      <td>-0.004162</td>\n",
              "      <td>0.033980</td>\n",
              "      <td>0.060616</td>\n",
              "      <td>0.003914</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>-0.001267</td>\n",
              "      <td>-0.010649</td>\n",
              "      <td>0.000785</td>\n",
              "      <td>-0.010385</td>\n",
              "      <td>0.030322</td>\n",
              "      <td>-0.005674</td>\n",
              "      <td>-0.004864</td>\n",
              "      <td>0.023667</td>\n",
              "      <td>-0.035549</td>\n",
              "      <td>0.015029</td>\n",
              "      <td>0.021599</td>\n",
              "      <td>-0.018164</td>\n",
              "      <td>0.033212</td>\n",
              "      <td>-0.003252</td>\n",
              "      <td>0.016526</td>\n",
              "      <td>-0.002808</td>\n",
              "      <td>0.026311</td>\n",
              "      <td>-0.035708</td>\n",
              "      <td>-0.018678</td>\n",
              "      <td>-0.002373</td>\n",
              "      <td>-0.028662</td>\n",
              "      <td>-0.035123</td>\n",
              "      <td>-0.003385</td>\n",
              "      <td>0.045884</td>\n",
              "      <td>0.011665</td>\n",
              "      <td>-0.014052</td>\n",
              "      <td>-0.061726</td>\n",
              "      <td>0.014183</td>\n",
              "      <td>-0.022871</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>0.012162</td>\n",
              "      <td>-0.002471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.071431</td>\n",
              "      <td>0.060319</td>\n",
              "      <td>0.054391</td>\n",
              "      <td>0.044092</td>\n",
              "      <td>0.010027</td>\n",
              "      <td>-0.040983</td>\n",
              "      <td>-0.001835</td>\n",
              "      <td>0.037287</td>\n",
              "      <td>0.003647</td>\n",
              "      <td>-0.019347</td>\n",
              "      <td>0.033744</td>\n",
              "      <td>0.044975</td>\n",
              "      <td>0.006248</td>\n",
              "      <td>0.010431</td>\n",
              "      <td>-0.044625</td>\n",
              "      <td>0.013033</td>\n",
              "      <td>-0.002135</td>\n",
              "      <td>0.018243</td>\n",
              "      <td>0.023759</td>\n",
              "      <td>-0.017309</td>\n",
              "      <td>0.005148</td>\n",
              "      <td>0.020520</td>\n",
              "      <td>0.015277</td>\n",
              "      <td>-0.016387</td>\n",
              "      <td>-0.015938</td>\n",
              "      <td>0.025628</td>\n",
              "      <td>0.013172</td>\n",
              "      <td>0.000948</td>\n",
              "      <td>-0.002931</td>\n",
              "      <td>-0.051095</td>\n",
              "      <td>0.007147</td>\n",
              "      <td>0.016390</td>\n",
              "      <td>0.018934</td>\n",
              "      <td>0.003266</td>\n",
              "      <td>-0.017015</td>\n",
              "      <td>0.011900</td>\n",
              "      <td>0.024302</td>\n",
              "      <td>0.023572</td>\n",
              "      <td>0.023524</td>\n",
              "      <td>0.018036</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017934</td>\n",
              "      <td>-0.007157</td>\n",
              "      <td>0.003441</td>\n",
              "      <td>-0.023176</td>\n",
              "      <td>0.025346</td>\n",
              "      <td>-0.037962</td>\n",
              "      <td>0.002921</td>\n",
              "      <td>0.008509</td>\n",
              "      <td>-0.015310</td>\n",
              "      <td>0.010629</td>\n",
              "      <td>0.003434</td>\n",
              "      <td>-0.009625</td>\n",
              "      <td>-0.030952</td>\n",
              "      <td>0.030623</td>\n",
              "      <td>0.010538</td>\n",
              "      <td>0.005693</td>\n",
              "      <td>-0.024166</td>\n",
              "      <td>-0.021443</td>\n",
              "      <td>-0.015510</td>\n",
              "      <td>-0.010230</td>\n",
              "      <td>0.037761</td>\n",
              "      <td>0.006454</td>\n",
              "      <td>0.011309</td>\n",
              "      <td>-0.005952</td>\n",
              "      <td>-0.015409</td>\n",
              "      <td>0.006979</td>\n",
              "      <td>-0.003098</td>\n",
              "      <td>-0.019273</td>\n",
              "      <td>-0.018461</td>\n",
              "      <td>0.002302</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.019827</td>\n",
              "      <td>0.035679</td>\n",
              "      <td>0.015561</td>\n",
              "      <td>-0.003557</td>\n",
              "      <td>-0.017377</td>\n",
              "      <td>0.031577</td>\n",
              "      <td>-0.035402</td>\n",
              "      <td>-0.005945</td>\n",
              "      <td>-0.029958</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       497       498       499\n",
              "0 -0.012012 -0.043367  0.039508  ...  0.032527  0.024831 -0.025416\n",
              "1 -0.069546  0.030708 -0.073707  ...  0.002024  0.002787 -0.037025\n",
              "2 -0.067972  0.046724 -0.119317  ... -0.010895 -0.001175 -0.024603\n",
              "3 -0.000930 -0.044648  0.008711  ...  0.014200  0.012162 -0.002471\n",
              "4 -0.071431  0.060319  0.054391  ... -0.035402 -0.005945 -0.029958\n",
              "\n",
              "[5 rows x 500 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyQy8Z5GROzN"
      },
      "source": [
        "Creating a Confusion Matrix and Calculating Accuracy, Precision , Recall and F scoreof the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L_FpnUeoOsQ",
        "outputId": "7b37144f-911d-4cd6-a4cc-b7927455d75c"
      },
      "source": [
        "def confusion_matrixs(y, yp):\n",
        "  #k = sorted(y.unique())\n",
        "  k = sorted(list(set(y)))\n",
        "  df = pd.DataFrame(index=k, columns=k)\n",
        "  df.fillna(0, inplace=True)\n",
        "  for i, j in zip(y, yp):\n",
        "    df.loc[i, j] += 1\n",
        "  sns.heatmap(df, annot=True)\n",
        "  plt.plot()\n",
        "train_x,test_x,train_y,test_y = train_test_split(x1,y, random_state = 56,test_size=0.2,stratify=y)\n",
        "X_train,y_train,X_test,y_test=train_x,train_y,test_x,test_y\n",
        "sgdl = SGDClassifier(eta0=0.0001, alpha=0.0001, loss='hinge',random_state=15, penalty='elasticnet', tol=1e-3,learning_rate='optimal')\n",
        "sgdl.fit(X_train, y_train)\n",
        "print(f'train accuracy: {sgdl.score(X_train, y_train)}')\n",
        "accuracy = accuracy_score(y_test, sgdl.predict(X_test))\n",
        "conf_mat = confusion_matrix(y_test,sgdl.predict(X_test))\n",
        "c=np.array([[i] for i in np.append(np.array([[i] for i in sgdl.coef_[0]]),[0])])\n",
        "print(\"The accuracy of the model is :\", round(accuracy,3)*100,\"%\")\n",
        "print(\"Confusion Matrix:\\n\",conf_mat)\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(y_test,sgdl.predict(X_test), average='weighted')\n",
        "print('Precision = ',round(precision,4),'\\nRecall = ', round(recall,4), '\\nF-Score = ',round(fscore,4))\n",
        "#confusion_matrixs(y_test, sgdl.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy: 0.8167164179104478\n",
            "The accuracy of the model is : 81.5 %\n",
            "Confusion Matrix:\n",
            " [[1356    2    2    12    3]\n",
            " [ 189     1    6    5     9]\n",
            " [  29     5    2    1     0]\n",
            " [  92     3   14    4    10]\n",
            " [  77     1    1    7     1]]\n",
            "Precision =  0.7013 \n",
            "Recall =  0.8152 \n",
            "F-Score =  0.7327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33TLgpKwofVW"
      },
      "source": [
        "**Multi Layer Perceptron**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeuyTv4joZs-",
        "outputId": "4d83b84c-baaf-417e-a963-de0d9dc9aabf"
      },
      "source": [
        "ANN_clf = MLPClassifier(hidden_layer_sizes=(500,250,50,10),activation='relu', solver='adam')\n",
        "X_train=train_x\n",
        "X_test=test_x\n",
        "ANN_clf.fit(X_train,train_y)\n",
        "print('Training Accuracy :',ANN_clf.score(X_train,train_y))\n",
        "print('Testing Accuracy :',ANN_clf.score(X_test,test_y))\n",
        "print(classification_report(test_y,ANN_clf.predict(X_test) ))\n",
        "print(confusion_matrix(test_y, ANN_clf.predict(X_test)))\n",
        "precision, recall, fscore, support = precision_recall_fscore_support(test_y, ANN_clf.predict(X_test), average='weighted')\n",
        "print('Precision = ',round(precision,4),'\\nRecall = ', round(recall,4), '\\nF-Score = ',round(fscore,4))\n",
        "confusion_matrixs(y_test, ANN_clf.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy : 0.9997611940298508\n",
            "Testing Accuracy : 0.7693409742120344\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.89      1706\n",
            "           1       0.18      0.15      0.17       189\n",
            "           2       0.08      0.03      0.05        29\n",
            "           3       0.05      0.01      0.02        92\n",
            "           4       0.12      0.09      0.10        78\n",
            "\n",
            "    accuracy                           0.77      2094\n",
            "   macro avg       0.26      0.24      0.24      2094\n",
            "weighted avg       0.72      0.77      0.74      2094\n",
            "\n",
            "[[1573   90    4    9   30]\n",
            " [ 145   29    2    6    7]\n",
            " [  20    3    1    1    4]\n",
            " [  57   21    1    1   12]\n",
            " [  45   17    4    5    7]]\n",
            "Precision =  0.7203 \n",
            "Recall =  0.7693 \n",
            "F-Score =  0.743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn3DmTsKoveF"
      },
      "source": [
        "**Bi-directional LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DRlMs7Voi3s",
        "outputId": "c9c01406-8522-4792-e89a-cddd96575340"
      },
      "source": [
        "vocab_size = 5000\n",
        "embedding_dim = 64\n",
        "max_length = 200\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "training_portion = .8\n",
        "\n",
        "articles  = df['text']\n",
        "labels = df['label']\n",
        "\n",
        "train_size = int(len(articles) * training_portion)\n",
        "\n",
        "train_articles = articles[0: train_size]\n",
        "train_labels = labels[0: train_size]\n",
        "\n",
        "validation_articles = articles[train_size:]\n",
        "validation_labels = labels[train_size:]\n",
        "\n",
        "print(train_size)\n",
        "print(len(train_articles))\n",
        "print(len(train_labels))\n",
        "print(len(validation_articles))\n",
        "print(len(validation_labels))\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(articles)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_articles)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_articles)\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "label_tokenizer = Tokenizer()\n",
        "label_tokenizer.fit_on_texts(labels)\n",
        "training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
        "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))\n",
        "model = tf.keras.Sequential([\n",
        "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    # Add a Dense layer with 6 units and softmax activation.\n",
        "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
        "    tf.keras.layers.Dense(6,activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "num_epochs = 10\n",
        "es = EarlyStopping(patience=2)\n",
        "mc=ModelCheckpoint('time_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)\n",
        "callbacks = [mc,es]\n",
        "history = model.fit(train_padded, training_label_seq, callbacks=callbacks,epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8375\n",
            "8375\n",
            "8375\n",
            "2094\n",
            "2094\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          320000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 128)        66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 429,542\n",
            "Trainable params: 429,542\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.61874, saving model to time_model.h5\n",
            "262/262 - 59s - loss: 0.7312 - accuracy: 0.8117 - val_loss: 0.6187 - val_accuracy: 0.8171 - 59s/epoch - 226ms/step\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.61874 to 0.61702, saving model to time_model.h5\n",
            "262/262 - 47s - loss: 0.5524 - accuracy: 0.8172 - val_loss: 0.6170 - val_accuracy: 0.8195 - 47s/epoch - 181ms/step\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.61702\n",
            "262/262 - 47s - loss: 0.4663 - accuracy: 0.8325 - val_loss: 0.6749 - val_accuracy: 0.8128 - 47s/epoch - 181ms/step\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.61702\n",
            "262/262 - 48s - loss: 0.3892 - accuracy: 0.8611 - val_loss: 0.7387 - val_accuracy: 0.7751 - 48s/epoch - 182ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjHG8VZC06H2"
      },
      "source": [
        "import pickle\n",
        "model = tf.keras.models.load_model('time_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDBr8lc9SQCC"
      },
      "source": [
        "The Following Graph shows that training and validation Accuracy increases with each epoch, where as loss decreases with each epoch. though there is some dip at 7th epoch, by the end of 10 epochs the accuracy gradually increased and loss gradually decreased."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "0IQLNVk8MvRW",
        "outputId": "5acdb6ba-ef4c-471a-8b63-b9dc83db30b4"
      },
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrWdzyaJpVeK",
        "outputId": "77d271dd-09cb-4e0f-ea32-6d6d10612e6c"
      },
      "source": [
        "scores = model.evaluate(validation_padded, validation_label_seq, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 81.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-0SoH-IpC3l",
        "outputId": "c63ebdc7-ae05-48c0-ccd2-c55e173a813f"
      },
      "source": [
        "txt = df['text'][random.randrange(0,len(df))]\n",
        "seq = tokenizer.texts_to_sequences(txt)\n",
        "padded = pad_sequences(seq, maxlen=max_length)\n",
        "pred = model.predict(padded)\n",
        "labels = ['0', '1', '3', '4', '2']\n",
        "k=[]\n",
        "for i in range(pred.shape[1]):\n",
        "  l=[]\n",
        "  for j in range(pred.shape[0]):\n",
        "      l.append(pred[j][i])\n",
        "  k.append(sum(l))\n",
        "print(labels[np.argmax(k)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR6Ax24khRcG"
      },
      "source": [
        "**TensorFlow Roberta Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fSAETNWaUON",
        "outputId": "02464437-58be-4c90-990f-d333f4cd2a8e"
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy (you can see that it is pretty easy to set up).\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set (always set in Kaggle)\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    #print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "#print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "MODEL_NAME = 'roberta-base'\n",
        "MAX_LEN = 256\n",
        "#ARTIFACTS_PATH = '../artifacts/'\n",
        "\n",
        "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
        "EPOCHS = 3\n",
        "\n",
        "'''if not os.path.exists(ARTIFACTS_PATH):\n",
        "    os.makedirs(ARTIFACTS_PATH)'''\n",
        "X_data = df[['text']].to_numpy().reshape(-1)\n",
        "y_data = df[['label']].to_numpy().reshape(-1)\n",
        "def roberta_encode(texts, tokenizer):\n",
        "    ct = len(texts)\n",
        "    input_ids = np.ones((ct, MAX_LEN), dtype='int32')\n",
        "    attention_mask = np.zeros((ct, MAX_LEN), dtype='int32')\n",
        "    token_type_ids = np.zeros((ct, MAX_LEN), dtype='int32') # Not used in text classification\n",
        "\n",
        "    for k, text in enumerate(texts):\n",
        "        # Tokenize\n",
        "        tok_text = tokenizer.tokenize(text)\n",
        "        \n",
        "        # Truncate and convert tokens to numerical IDs\n",
        "        enc_text = tokenizer.convert_tokens_to_ids(tok_text[:(MAX_LEN-2)])\n",
        "        \n",
        "        input_length = len(enc_text) + 2\n",
        "        input_length = input_length if input_length < MAX_LEN else MAX_LEN\n",
        "        \n",
        "        # Add tokens [CLS] and [SEP] at the beginning and the end\n",
        "        input_ids[k,:input_length] = np.asarray([0] + enc_text + [2], dtype='int32')\n",
        "        \n",
        "        # Set to 1s in the attention input\n",
        "        attention_mask[k,:input_length] = 1\n",
        "\n",
        "    return {\n",
        "        'input_word_ids': input_ids,\n",
        "        'input_mask': attention_mask,\n",
        "        'input_type_ids': token_type_ids\n",
        "    }\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=777)\n",
        "# Import tokenizer from HuggingFace\n",
        "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
        "X_train = roberta_encode(X_train, tokenizer)\n",
        "X_test = roberta_encode(X_test, tokenizer)\n",
        "\n",
        "y_train = np.asarray(y_train, dtype='int32')\n",
        "y_test = np.asarray(y_test, dtype='int32')\n",
        "with strategy.scope():\n",
        "    roberta_model = TFRobertaModel.from_pretrained(MODEL_NAME)\n",
        "def build_model(n_categories,roberta_model):\n",
        "    with strategy.scope():\n",
        "        input_word_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "        input_mask = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_mask')\n",
        "        input_type_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_type_ids')\n",
        "\n",
        "        # Import RoBERTa model from HuggingFace\n",
        "        \n",
        "        x = roberta_model(input_word_ids, attention_mask=input_mask, token_type_ids=input_type_ids)\n",
        "\n",
        "        # Huggingface transformers have multiple outputs, embeddings are the first one,\n",
        "        # so let's slice out the first position\n",
        "        x = x[0]\n",
        "\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = tf.keras.layers.Dense(256, activation='tanh')(x)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        x = tf.keras.layers.Dense(128, activation='tanh')(x)\n",
        "        x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        x = tf.keras.layers.Dense(40, activation='tanh')(x)\n",
        "        x = tf.keras.layers.Dense(n_categories, activation='softmax')(x)\n",
        "\n",
        "        model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=x)\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "with strategy.scope():\n",
        "    model = build_model(len(df['label'].unique()),roberta_model)\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.58.38.178:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.58.38.178:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.58.38.178:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.58.38.178:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_type_ids (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  124645632  ['input_word_ids[0][0]',         \n",
            " odel)                          thPoolingAndCrossAt               'input_mask[0][0]',             \n",
            "                                tentions(last_hidde               'input_type_ids[0][0]']         \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 256, 768)     0           ['tf_roberta_model_1[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 196608)       0           ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256)          50331904    ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_76 (Dropout)           (None, 256)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 128)          32896       ['dropout_76[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_77 (Dropout)           (None, 128)          0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 40)           5160        ['dropout_77[0][0]']             \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 5)            205         ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 175,015,797\n",
            "Trainable params: 175,015,797\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGuxCEVWidkM",
        "outputId": "9fa9c7cd-0d1a-4a6a-972b-a224391af2f8"
      },
      "source": [
        "with strategy.scope():\n",
        "    print('Training...')\n",
        "    history = model.fit(X_train,\n",
        "                        y_train,\n",
        "                        epochs=4,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        verbose=1,\n",
        "                        validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n",
            "Epoch 1/4\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_24:0' shape=(None,) dtype=int32>]\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2970: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use `experimental_local_results` instead.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_24:0' shape=(None,) dtype=int32>]\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "115/115 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.8140INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 256) dtype=int32>, <tf.Tensor 'cond/Identity_24:0' shape=(None,) dtype=int32>]\n",
            "115/115 [==============================] - 167s 741ms/step - loss: 0.6252 - accuracy: 0.8140 - val_loss: 0.5856 - val_accuracy: 0.8074\n",
            "Epoch 2/4\n",
            "115/115 [==============================] - 22s 188ms/step - loss: 0.5353 - accuracy: 0.8610 - val_loss: 0.5611 - val_accuracy: 0.8450\n",
            "Epoch 3/4\n",
            "115/115 [==============================] - 28s 225ms/step - loss: 0.4968 - accuracy: 0.8912 - val_loss: 0.4628 - val_accuracy: 0.8796\n",
            "Epoch 4/4\n",
            "115/115 [==============================] - 21s 180ms/step - loss: 0.2716 - accuracy: 0.9210 - val_loss: 0.5611 - val_accuracy: 0.9129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc8K1R-KTswn"
      },
      "source": [
        "Accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFDsjE5bhp4-",
        "outputId": "03bc72e3-76ff-4585-db41-efe1ac07282d"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5KrFNiGI2dI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}